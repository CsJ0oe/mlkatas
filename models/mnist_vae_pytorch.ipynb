{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a self-correcting activity generated by [nbgrader](https://nbgrader.readthedocs.io). Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate handwritten digits with a VAE (PyTorch)\n",
    "\n",
    "The goal here is to train a VAE to generate handwritten digits.\n",
    "\n",
    "![VAE digits](images/vae_digits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(\"GPU found :)\" if torch.cuda.is_available() else \"No GPU :(\")\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create batch data loaders `trainloader` and `testloader` resp. for training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af1c62cd8f2c6b61d53831111324fed",
     "grade": true,
     "grade_id": "cell-7ee6e64de897e788",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "### Question\n",
    "\n",
    "Complete the following class to create a variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a41ad65b45e378060e1180f987522c1",
     "grade": true,
     "grade_id": "cell-aeffbaacaac863dc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc5 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input into its latent representation\n",
    "        Returns mean and standard deviation\"\"\"\n",
    "        \n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def sample(self, mu, log_var):\n",
    "        \"\"\"Sample a random codings vector from a gaussian distribution\n",
    "        Takes mean and log_var (gamma) as parameters\"\"\"\n",
    "        \n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode codings\"\"\"\n",
    "        \n",
    "        h = F.relu(self.fc4(z))\n",
    "        return torch.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Encode inputs to obtain mean and standard deviation\n",
    "           Sample codings from gaussian distribution using mean and std\n",
    "           Returns decoded codings, mean and standard deviation\"\"\"\n",
    "        # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "### Question\n",
    "\n",
    "Complete the following training loop to:\n",
    "- instantiate the variational autoencoder on target device;\n",
    "- instanciate the Adam optimizer;\n",
    "- implement forward pass and gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea89e30b5786d034e82f8c0ae01abe63",
     "grade": true,
     "grade_id": "cell-11f1ec283e7cd535",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "num_epochs = 15\n",
    "learning_rate = 1e-3\n",
    "step_count = len(trainloader)\n",
    "prints_per_epoch = 1  # Increase to see more feedback during training\n",
    "\n",
    "# Instanciate VAE and optimizer\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Train model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(trainloader):\n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # Compute reconstruction loss and KL divergence\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction=\"sum\")\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = reconst_loss + kl_div\n",
    "\n",
    "        # Backprop and optimize\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # Print losses at regular intervals\n",
    "        print_threshold = math.ceil(step_count / prints_per_epoch)\n",
    "        if (i + 1) % print_threshold == 0 or (i + 1) == step_count:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}]\"\n",
    "                f\", step [{i + 1}/{step_count}]\"\n",
    "                f\", reconst loss: {reconst_loss.item():.4f}\"\n",
    "                f\", KL div: {kl_div.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructions visualization¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    # Convert PyTorch tensor to NumPy\n",
    "    img_tensor = image.cpu().numpy() if torch.cuda.is_available() else image.numpy()\n",
    "    plt.imshow(img_tensor.squeeze(), cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, images, n_images=8):\n",
    "    \"\"\"Show original and reconstructed images side-by-side\"\"\"\n",
    "    \n",
    "    inputs = images.reshape(-1, 28*28).to(device)\n",
    "    reconstructions, _, _ = model(inputs)\n",
    "    \n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index].view(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Show reconstructions for one batch of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "010911be05113bb3a62264e3800a0e1f",
     "grade": true,
     "grade_id": "cell-6927b3114069f46f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    \"\"\"Show a series of images\"\"\"\n",
    "\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols * 1.5, 3))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plot_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Use the VAE to show several generated digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4b694aae1da7ed57a3c2d7ba1a3134",
     "grade": true,
     "grade_id": "cell-58f40750d5551290",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(16, latent_dim).to(device)\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
